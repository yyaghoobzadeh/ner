{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'corpora/conll2002' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/yy1/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa5a6da16c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconll2002\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yy1/anaconda/lib/python2.7/site-packages/nltk/corpus/util.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yy1/anaconda/lib/python2.7/site-packages/nltk/corpus/util.pyc\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'corpora/conll2002' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/yy1/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "nltk.corpus.conll2002.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: __main__.py [options]\n",
      "\n",
      "__main__.py: error: option -f: invalid integer value: '/Users/yy1/Library/Jupyter/runtime/kernel-9a335666-d1e8-44c7-ba6a-51bdd7efbe09.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Sep 10, 2016\n",
    "\n",
    "@author: yy1\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import optparse\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "from utils import create_input\n",
    "import loader\n",
    "\n",
    "from utils import models_path, evaluate, eval_script, eval_temp\n",
    "from loader import word_mapping, char_mapping, tag_mapping\n",
    "from loader import update_tag_scheme, prepare_dataset\n",
    "from loader import augment_with_pretrained\n",
    "\n",
    "class CRF_NER(object):\n",
    "    '''\n",
    "    NER with CRF\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self, params):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read parameters from command line\n",
    "    optparser = optparse.OptionParser()\n",
    "    optparser.add_option(\n",
    "        \"-T\", \"--train\", default=\"\",\n",
    "        help=\"Train set location\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-d\", \"--dev\", default=\"\",\n",
    "        help=\"Dev set location\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-t\", \"--test\", default=\"\",\n",
    "        help=\"Test set location\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-s\", \"--tag_scheme\", default=\"iobes\",\n",
    "        help=\"Tagging scheme (IOB or IOBES)\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-l\", \"--lower\", default=\"0\",\n",
    "        type='int', help=\"Lowercase words (this will not affect character inputs)\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-z\", \"--zeros\", default=\"0\",\n",
    "        type='int', help=\"Replace digits with 0\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-p\", \"--pre_emb\", default=\"\",\n",
    "        help=\"Location of pretrained embeddings\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-a\", \"--cap_dim\", default=\"0\",\n",
    "        type='int', help=\"Capitalization feature dimension (0 to disable)\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-f\", \"--crf\", default=\"1\",\n",
    "        type='int', help=\"Use CRF (0 to disable)\"\n",
    "    )\n",
    "    opts = optparser.parse_args()[0]\n",
    "\n",
    "    # Parse parameters\n",
    "    parameters = OrderedDict()\n",
    "    parameters['tag_scheme'] = opts.tag_scheme\n",
    "    parameters['lower'] = opts.lower == 1\n",
    "    parameters['zeros'] = opts.zeros == 1\n",
    "    parameters['pre_emb'] = opts.pre_emb\n",
    "    parameters['cap_dim'] = opts.cap_dim\n",
    "    parameters['crf'] = opts.crf == 1\n",
    "    \n",
    "    # Check parameters validity\n",
    "    assert os.path.isfile(opts.train)\n",
    "    assert os.path.isfile(opts.dev)\n",
    "    assert os.path.isfile(opts.test)\n",
    "    assert parameters['tag_scheme'] in ['iob', 'iobes']\n",
    "    assert not parameters['all_emb'] or parameters['pre_emb']\n",
    "    assert not parameters['pre_emb'] or parameters['word_dim'] > 0\n",
    "    assert not parameters['pre_emb'] or os.path.isfile(parameters['pre_emb'])\n",
    "\n",
    "        # Check evaluation script / folders\n",
    "    if not os.path.isfile(eval_script):\n",
    "        raise Exception('CoNLL evaluation script not found at \"%s\"' % eval_script)\n",
    "    if not os.path.exists(eval_temp):\n",
    "        os.makedirs(eval_temp)\n",
    "    if not os.path.exists(models_path):\n",
    "        os.makedirs(models_path)\n",
    "    \n",
    "    # Data parameters\n",
    "    lower = parameters['lower']\n",
    "    zeros = parameters['zeros']\n",
    "    tag_scheme = parameters['tag_scheme']\n",
    "        \n",
    "    train_sentences = loader.load_sentences(opts.train, lower, zeros)\n",
    "    dev_sentences = loader.load_sentences(opts.dev, lower, zeros)\n",
    "    test_sentences = loader.load_sentences(opts.test, lower, zeros)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: __main__.py [options]\n",
      "\n",
      "__main__.py: error: option -f: invalid integer value: '/Users/yy1/Library/Jupyter/runtime/kernel-3af1853a-6596-4749-806a-a74c1cc6791d.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Sep 10, 2016\n",
    "\n",
    "@author: yy1\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import optparse\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "from utils import create_input\n",
    "import loader\n",
    "\n",
    "from utils import models_path, evaluate, eval_script, eval_temp\n",
    "from loader import word_mapping, char_mapping, tag_mapping\n",
    "from loader import update_tag_scheme, prepare_dataset\n",
    "from loader import augment_with_pretrained\n",
    "from pygments.lexer import words\n",
    "import nltk\n",
    "\n",
    "class CRF_NER(object):\n",
    "    '''\n",
    "    NER with CRF\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self, params):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            '-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            '+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]  \n",
    "\n",
    "def add_pos_tags(sents):\n",
    "    '''\n",
    "    example sents[0] = [[u'breaking', u'B-NEWSTYPE'], [u'news', u'I-NEWSTYPE'], [u'dealing', u'O'], [u'with', u'O'], [u'prime', u'B-KEYWORDS'], [u'minister', u'I-KEYWORDS'], [u'of', u'I-KEYWORDS'], [u'greece', u'I-KEYWORDS'], [u's', u'I-KEYWORDS'], [u'visit', u'I-KEYWORDS'], [u'to', u'I-KEYWORDS'], [u'tunis', u'I-KEYWORDS'], [u'in', u'O'], [u'west', u'B-PROVIDER'], [u'shore', u'I-PROVIDER'], [u'news', u'I-PROVIDER']]\n",
    "    '''\n",
    "    sents_posadded = []\n",
    "    for sent in sents:\n",
    "        words = [part[0] for part in sent]\n",
    "        ner_tags = [part[1] for part in sent]\n",
    "#         text = nltk.word_tokenize(u' '.join(words))\n",
    "#         print text\n",
    "        word_tags = nltk.pos_tag(words)\n",
    "        word_pos_tags = [(word_pos[0],word_pos[1],nertag) for word_pos, nertag in zip(word_tags, ner_tags)]\n",
    "        sents_posadded.append(word_pos_tags)\n",
    "    return sents_posadded\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read parameters from command line\n",
    "    optparser = optparse.OptionParser()\n",
    "    optparser.add_option(\n",
    "        \"-T\", \"--train\", default=\"\",\n",
    "        help=\"Train set location\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-d\", \"--dev\", default=\"\",\n",
    "        help=\"Dev set location\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-t\", \"--test\", default=\"\",\n",
    "        help=\"Test set location\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-s\", \"--tag_scheme\", default=\"iob\",\n",
    "        help=\"Tagging scheme (IOB or IOBES)\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-l\", \"--lower\", default=\"1\",\n",
    "        type='int', help=\"Lowercase words (this will not affect character inputs)\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-z\", \"--zeros\", default=\"1\",\n",
    "        type='int', help=\"Replace digits with 0\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-p\", \"--pre_emb\", default=\"\",\n",
    "        help=\"Location of pretrained embeddings\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-a\", \"--cap_dim\", default=\"0\",\n",
    "        type='int', help=\"Capitalization feature dimension (0 to disable)\"\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-f\", \"--crf\", default=\"1\",\n",
    "        type='int', help=\"Use CRF (0 to disable)\"\n",
    "    )\n",
    "    opts = optparser.parse_args()[0]\n",
    "\n",
    "    # Parse parameters\n",
    "    parameters = OrderedDict()\n",
    "    parameters['tag_scheme'] = opts.tag_scheme\n",
    "    parameters['lower'] = opts.lower == 1\n",
    "    parameters['zeros'] = opts.zeros == 1\n",
    "    parameters['pre_emb'] = opts.pre_emb\n",
    "    parameters['cap_dim'] = opts.cap_dim\n",
    "    parameters['crf'] = opts.crf == 1\n",
    "    \n",
    "    # Check parameters validity\n",
    "    assert os.path.isfile(opts.train)\n",
    "    assert os.path.isfile(opts.dev)\n",
    "    assert os.path.isfile(opts.test)\n",
    "    assert parameters['tag_scheme'] in ['iob', 'iobes']\n",
    "#     assert not parameters['pre_emb'] or parameters['word_dim'] > 0\n",
    "\n",
    "        # Check evaluation script / folders\n",
    "    if not os.path.isfile(eval_script):\n",
    "        raise Exception('CoNLL evaluation script not found at \"%s\"' % eval_script)\n",
    "    if not os.path.exists(eval_temp):\n",
    "        os.makedirs(eval_temp)\n",
    "    if not os.path.exists(models_path):\n",
    "        os.makedirs(models_path)\n",
    "    \n",
    "    # Data parameters\n",
    "    lower = parameters['lower']\n",
    "    zeros = parameters['zeros']\n",
    "    tag_scheme = parameters['tag_scheme']\n",
    "        \n",
    "    train_sentences = loader.load_sentences(opts.train, lower, zeros)\n",
    "    dev_sentences = loader.load_sentences(opts.dev, lower, zeros)\n",
    "    test_sentences = loader.load_sentences(opts.test, lower, zeros)\n",
    "    \n",
    "    print train_sentences[0]\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    train_sentences = add_pos_tags(train_sentences)\n",
    "    train_sentences = add_pos_tags(dev_sentences)\n",
    "    test_sentences = add_pos_tags(test_sentences)\n",
    "    \n",
    "    print train_sentences[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c8e0e1f03640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Use CRF (0 to disable)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     )\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Parse parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yy1/anaconda/lib/python2.7/optparse.pyc\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, values)\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBadOptionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptionValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlargs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yy1/anaconda/lib/python2.7/optparse.pyc\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \"\"\"\n\u001b[1;32m   1583\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s: error: %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prog_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yy1/anaconda/lib/python2.7/optparse.pyc\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, msg)\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1574\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
